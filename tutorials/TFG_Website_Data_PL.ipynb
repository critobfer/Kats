{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from kats.consts import TimeSeriesData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.kaggle.com/datasets/bobnau/daily-website-visitors/code\n",
    "daily_website_df = pd.read_csv(\"../kats/data/daily-website-visitors.csv\")\n",
    "daily_website_df.head()\n",
    "# Function to remove commas\n",
    "def remove_commas(x):\n",
    "    return float(x.replace(',', ''))\n",
    "# Apply the preprocessing functions\n",
    "\n",
    "daily_website_df['Date'] = pd.to_datetime(daily_website_df['Date'])\n",
    "daily_website_df['Page.Loads'] = daily_website_df['Page.Loads'].apply(lambda x : remove_commas(x))\n",
    "daily_website_df['Unique.Visits'] = daily_website_df['Unique.Visits'].apply(lambda x : remove_commas(x))\n",
    "daily_website_df['First.Time.Visits'] = daily_website_df['First.Time.Visits'].apply(lambda x : remove_commas(x))\n",
    "daily_website_df['Returning.Visits'] = daily_website_df['Returning.Visits'].apply(lambda x : remove_commas(x))\n",
    "daily_website_df['Day.Of.Week']\n",
    "df_mask=daily_website_df['Day.Of.Week']==2\n",
    "daily_website_df_monday = daily_website_df[df_mask]\n",
    "\n",
    "\n",
    "daily_website_df.drop(['Row','Day','Day.Of.Week','Returning.Visits'],inplace=True,axis=1)\n",
    "daily_website_df.columns = [\"time\", \"PageLoads\",\"UniqueVisits\", \"FirstTimeVisits\" ]\n",
    "\n",
    "daily_website_df_monday.drop(['Row','Day','Day.Of.Week','Returning.Visits'],inplace=True,axis=1)\n",
    "daily_website_df_monday.columns = [\"time\", \"PageLoads\",\"UniqueVisits\", \"FirstTimeVisits\" ]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "daily_website_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First visualitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_website_ts = TimeSeriesData(daily_website_df)\n",
    "\n",
    "daily_website_ts_monday = TimeSeriesData(daily_website_df_monday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot multiple time series from multi_ts by passing in the name of each value column we want to plot\n",
    "daily_website_ts[0:365].plot(cols=[\"PageLoads\",\"UniqueVisits\", \"FirstTimeVisits\"])\n",
    "plt.title('First year of Daily Website Data', fontsize = 30)\n",
    "plt.xlabel('time(days)')\n",
    "plt.ylabel('number')\n",
    "plt.savefig('../images/DWD_first_year', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot multiple time series from multi_ts by passing in the name of each value column we want to plot\n",
    "daily_website_ts.plot(cols=[\"PageLoads\",\"UniqueVisits\", \"FirstTimeVisits\"])\n",
    "# fig = plt.figure()\n",
    "plt.title('Daily Website Data', fontsize = 30)\n",
    "plt.xlabel('time(days)')\n",
    "plt.ylabel('number')\n",
    "plt.savefig('../images/DWD', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot multiple time series from multi_ts by passing in the name of each value column we want to plot\n",
    "daily_website_ts_monday.plot(cols=[\"PageLoads\",\"UniqueVisits\", \"FirstTimeVisits\"])\n",
    "plt.title('Mondays of Daily Website Data', fontsize = 30)\n",
    "plt.xlabel('time(weeks)')\n",
    "plt.ylabel('number')\n",
    "plt.savefig('../images/DWD_mondays', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_website_PL_ts = TimeSeriesData(daily_website_df.drop(['UniqueVisits','FirstTimeVisits'], axis=1))\n",
    "daily_website_PL_ts\n",
    "\n",
    "daily_website_UV_ts = TimeSeriesData(daily_website_df.drop(['PageLoads','FirstTimeVisits'], axis=1))\n",
    "daily_website_UV_ts\n",
    "\n",
    "daily_website_FTV_ts = TimeSeriesData(daily_website_df.drop(['PageLoads','UniqueVisits'], axis=1))\n",
    "daily_website_FTV_ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First comparative : PageLoads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPERPARAMETERS\n",
    "import kats.utils.time_series_parameter_tuning as tpt\n",
    "from kats.consts import ModelEnum, SearchMethodEnum, TimeSeriesData\n",
    "\n",
    "\n",
    "from ax.core.parameter import ChoiceParameter, FixedParameter, ParameterType\n",
    "from ax.models.random.sobol import SobolGenerator\n",
    "from ax.models.random.uniform import UniformGenerator\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "ts = daily_website_PL_ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.models.sarima import SARIMAModel, SARIMAParams\n",
    "parameters_grid_search = [\n",
    "{\n",
    "    \"name\": \"p\",\n",
    "    \"type\": \"choice\",\n",
    "    \"values\": list(range(1, 3)),\n",
    "    \"value_type\": \"int\",\n",
    "    \"is_ordered\": True,\n",
    "},\n",
    "{\n",
    "    \"name\": \"d\",\n",
    "    \"type\": \"choice\",\n",
    "    \"values\": list(range(1, 3)),\n",
    "    \"value_type\": \"int\",\n",
    "    \"is_ordered\": True,\n",
    "},\n",
    "{\n",
    "    \"name\": \"q\",\n",
    "    \"type\": \"choice\",\n",
    "    \"values\": list(range(1, 3)),\n",
    "    \"value_type\": \"int\",\n",
    "    \"is_ordered\": True,\n",
    "}\n",
    "]\n",
    "\n",
    "parameter_tuner_grid = tpt.SearchMethodFactory.create_search_method(\n",
    "    objective_name=\"evaluation_metric\",\n",
    "    parameters=parameters_grid_search,\n",
    "    selected_search_method=SearchMethodEnum.GRID_SEARCH,\n",
    ")\n",
    "\n",
    "\n",
    "# Divide into an 80/20 training-test split\n",
    "split = int(0.8*len(ts))\n",
    "\n",
    "train_ts = ts[0:split]\n",
    "test_ts = ts[split:]\n",
    "\n",
    "# Fit an ARIMA model and calculate the MAE for the test data\n",
    "def evaluation_function(params):\n",
    "    sarima_params = SARIMAParams(\n",
    "        p = params['p'],\n",
    "        d = params['d'],\n",
    "        q = params['q']\n",
    "    )\n",
    "    model = SARIMAModel(train_ts, sarima_params)\n",
    "    model.fit()\n",
    "    model_pred = model.predict(steps=len(test_ts))\n",
    "    error = np.mean(np.abs(model_pred['fcst'].values - test_ts.value.values))\n",
    "    return error\n",
    "\n",
    "\n",
    "parameter_tuner_grid.generate_evaluate_new_parameter_values(\n",
    "    evaluation_function=evaluation_function\n",
    ")\n",
    "\n",
    "# Retrieve parameter tuning results\n",
    "\n",
    "parameter_tuning_results_grid = (\n",
    "    parameter_tuner_grid.list_parameter_value_scores()\n",
    ")\n",
    "\n",
    "parameter_tuning_results_grid\n",
    "\n",
    "min = parameter_tuning_results_grid['mean'].min()\n",
    "\n",
    "parameter_tuning_results_grid[parameter_tuning_results_grid['mean']==min].parameters.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SARIMA param class\n",
    "sarima_params = SARIMAParams(\n",
    "    p = 2, \n",
    "    d = 1, \n",
    "    q = 2, \n",
    "    trend = 'ct', #both linear or constant\n",
    "    seasonal_order=(1,0,1,365) # Becouse the data have a weekly behaivour\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear y Cuadrático : sin parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.models.linear_model import LinearModelParams, LinearModel\n",
    "from kats.models.quadratic_model import QuadraticModelParams, QuadraticModel\n",
    "lin_params = LinearModelParams()\n",
    "qua_params = QuadraticModelParams()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.models.stlf import STLFModel, STLFParams\n",
    "parameters_grid_search = [\n",
    "{\n",
    "    \"name\": \"method\",\n",
    "    \"type\": \"choice\",\n",
    "    \"values\": ['theta','linear','quadratic'] ,\n",
    "    \"value_type\": \"str\",\n",
    "    \"is_ordered\": True,\n",
    "},\n",
    "{\n",
    "    \"name\": \"m\",\n",
    "    \"type\": \"choice\",\n",
    "    \"values\": [7,30,365],\n",
    "    \"value_type\": \"int\",\n",
    "    \"is_ordered\": True,\n",
    "}\n",
    "]\n",
    "\n",
    "parameter_tuner_grid = tpt.SearchMethodFactory.create_search_method(\n",
    "    objective_name=\"evaluation_metric\",\n",
    "    parameters=parameters_grid_search,\n",
    "    selected_search_method=SearchMethodEnum.GRID_SEARCH,\n",
    ")\n",
    "\n",
    "# Fit an ARIMA model and calculate the MAE for the test data\n",
    "def evaluation_function(params):\n",
    "    stlf_params =STLFParams(\n",
    "        method = params['method'],\n",
    "        m = params['m']\n",
    "    )\n",
    "    model =STLFModel(train_ts, stlf_params)\n",
    "    model.fit()\n",
    "    model_pred = model.predict(steps=len(test_ts))\n",
    "    error = np.mean(np.abs(model_pred['fcst'].values - test_ts.value.values))\n",
    "    return error\n",
    "\n",
    "\n",
    "parameter_tuner_grid.generate_evaluate_new_parameter_values(\n",
    "    evaluation_function=evaluation_function\n",
    ")\n",
    "\n",
    "# Retrieve parameter tuning results\n",
    "\n",
    "parameter_tuning_results_grid = (\n",
    "    parameter_tuner_grid.list_parameter_value_scores()\n",
    ")\n",
    "\n",
    "parameter_tuning_results_grid\n",
    "\n",
    "min = parameter_tuning_results_grid['mean'].min()\n",
    "\n",
    "parameter_tuning_results_grid[parameter_tuning_results_grid['mean']==min].parameters.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stlf_params = STLFParams(\n",
    "    method = 'theta',\n",
    "    m = 7\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.models.harmonic_regression import HarmonicRegressionModel, HarmonicRegressionParams\n",
    "parameters_grid_search = [\n",
    "{\n",
    "    \"name\": \"period\",\n",
    "    \"type\": \"choice\",\n",
    "    \"values\": [7,30,360] ,\n",
    "    \"value_type\": \"float\",\n",
    "    \"is_ordered\": True,\n",
    "},\n",
    "{\n",
    "    \"name\": \"fourier_order\",\n",
    "    \"type\": \"choice\",\n",
    "    \"values\": [4,5,6,7,8],\n",
    "    \"value_type\": \"int\",\n",
    "    \"is_ordered\": True,\n",
    "}\n",
    "]\n",
    "\n",
    "parameter_tuner_grid = tpt.SearchMethodFactory.create_search_method(\n",
    "    objective_name=\"evaluation_metric\",\n",
    "    parameters=parameters_grid_search,\n",
    "    selected_search_method=SearchMethodEnum.GRID_SEARCH,\n",
    ")\n",
    "\n",
    "# Fit an ARIMA model and calculate the MAE for the test data\n",
    "def evaluation_function(params):\n",
    "    hg_params =HarmonicRegressionParams(\n",
    "        period = params['period'],\n",
    "        fourier_order = params['fourier_order']\n",
    "    )\n",
    "    model =HarmonicRegressionModel(train_ts, hg_params)\n",
    "    model.fit()\n",
    "    model_pred = model.predict(dates  = test_ts.time)\n",
    "    error = np.mean(np.abs(model_pred['fcst'].values - test_ts.value.values))\n",
    "    return error\n",
    "\n",
    "\n",
    "parameter_tuner_grid.generate_evaluate_new_parameter_values(\n",
    "    evaluation_function=evaluation_function\n",
    ")\n",
    "\n",
    "# Retrieve parameter tuning results\n",
    "\n",
    "parameter_tuning_results_grid = (\n",
    "    parameter_tuner_grid.list_parameter_value_scores()\n",
    ")\n",
    "\n",
    "parameter_tuning_results_grid\n",
    "\n",
    "min = parameter_tuning_results_grid['mean'].min()\n",
    "\n",
    "parameter_tuning_results_grid[parameter_tuning_results_grid['mean']==min].parameters.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_params =HarmonicRegressionParams(\n",
    "        period = 30,\n",
    "        fourier_order = 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.utils.backtesters import BackTesterSimple\n",
    "\n",
    "\n",
    "backtester_simple_errors = {}\n",
    "ALL_ERRORS = ['mae','mape', 'mase', 'mse', 'rmse', 'smape']\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "backtester_simple_sarima = BackTesterSimple(\n",
    "    error_methods=ALL_ERRORS,\n",
    "    data=ts,\n",
    "    params= sarima_params,\n",
    "    train_percentage=80,\n",
    "    test_percentage=20, \n",
    "    model_class=SARIMAModel)\n",
    "\n",
    "backtester_simple_sarima.run_backtest()\n",
    "\n",
    "backtester_simple_errors['sarima'] = {}\n",
    "for error, value in backtester_simple_sarima.errors.items():\n",
    "    backtester_simple_errors['sarima'][error] = value\n",
    "\n",
    "# ###############################################################################\n",
    "# backtester_simple_hr = BackTesterSimple(\n",
    "#     error_methods=ALL_ERRORS,\n",
    "#     data=ts,\n",
    "#     params= hr_params,\n",
    "#     train_percentage=80,\n",
    "#     test_percentage=20, \n",
    "#     model_class=HarmonicRegressionModel)\n",
    "\n",
    "# backtester_simple_hr.run_backtest()\n",
    "\n",
    "# backtester_simple_errors['harmonic-regression'] = {}\n",
    "# for error, value in backtester_simple_hr.errors.items():\n",
    "#     backtester_simple_errors['harmonic-regression'][error] = value\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "backtester_simple_lin = BackTesterSimple(\n",
    "    error_methods=ALL_ERRORS,\n",
    "    data=ts,\n",
    "    params = lin_params,\n",
    "    train_percentage=80,\n",
    "    test_percentage=20, \n",
    "    model_class= LinearModel)\n",
    "\n",
    "backtester_simple_lin.run_backtest()\n",
    "\n",
    "backtester_simple_errors['linear'] = {}\n",
    "for error, value in backtester_simple_lin.errors.items():\n",
    "    backtester_simple_errors['linear'][error] = value\n",
    "\n",
    "###############################################################################\n",
    "backtester_simple_qua = BackTesterSimple(\n",
    "    error_methods=ALL_ERRORS,\n",
    "    data=ts,\n",
    "    params = qua_params,\n",
    "    train_percentage=80,\n",
    "    test_percentage=20, \n",
    "    model_class= QuadraticModel)\n",
    "\n",
    "backtester_simple_qua.run_backtest()\n",
    "\n",
    "backtester_simple_errors['quadratic'] = {}\n",
    "for error, value in backtester_simple_qua.errors.items():\n",
    "    backtester_simple_errors['quadratic'][error] = value\n",
    "\n",
    "###############################################################################\n",
    "backtester_simple_stlf = BackTesterSimple(\n",
    "    error_methods=ALL_ERRORS,\n",
    "    data=ts,\n",
    "    params = stlf_params,\n",
    "    train_percentage=80,\n",
    "    test_percentage=20, \n",
    "    model_class= STLFModel)\n",
    "\n",
    "backtester_simple_stlf.run_backtest()\n",
    "\n",
    "backtester_simple_errors['stlf'] = {}\n",
    "for error, value in backtester_simple_stlf.errors.items():\n",
    "    backtester_simple_errors['stlf'][error] = value\n",
    "\n",
    "\n",
    "pd.DataFrame.from_dict(backtester_simple_errors) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.models.ensemble.ensemble import EnsembleParams, BaseModelParams\n",
    "from kats.models.ensemble.kats_ensemble import KatsEnsemble\n",
    "model_ensemble_params = EnsembleParams(\n",
    "            [\n",
    "                BaseModelParams(\"sarima\",sarima_params),\n",
    "                BaseModelParams(\"linear\", lin_params),\n",
    "                BaseModelParams(\"quadratic\", qua_params)\n",
    "                # BaseModelParams(\"stlf\", stlf_params)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "from kats.models.ensemble.bates_granger_ensemble import BatesGrangerEnsemble\n",
    "from kats.models.ensemble.weighted_avg_ensemble import WeightedAvgEnsemble\n",
    "from kats.models.ensemble.mean_ensemble import MeanEnsembleModel\n",
    "from kats.models.ensemble.median_ensemble import MedianEnsembleModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtester_ensemble_errors = {}\n",
    "ALL_ERRORS = ['mae','mape', 'mase', 'mse', 'rmse', 'smape']\n",
    "###############################################################################\n",
    "backtester_ensemble_median = BackTesterSimple(\n",
    "    error_methods=ALL_ERRORS,\n",
    "    data=ts,\n",
    "    params= model_ensemble_params,\n",
    "    train_percentage=80,\n",
    "    test_percentage=20,\n",
    "    model_class=MedianEnsembleModel)\n",
    "\n",
    "backtester_ensemble_median.run_backtest()\n",
    "\n",
    "backtester_ensemble_errors['median'] = {}\n",
    "for error, value in backtester_ensemble_median.errors.items():\n",
    "    backtester_ensemble_errors['median'][error] = value\n",
    "###############################################################################\n",
    "backtester_ensemble_mean = BackTesterSimple(\n",
    "    error_methods=ALL_ERRORS,\n",
    "    data=ts,\n",
    "    params= model_ensemble_params,\n",
    "    train_percentage=80,\n",
    "    test_percentage=20, \n",
    "    model_class=MeanEnsembleModel)\n",
    "\n",
    "backtester_ensemble_mean.run_backtest()\n",
    "\n",
    "backtester_ensemble_errors['mean'] = {}\n",
    "for error, value in backtester_ensemble_mean.errors.items():\n",
    "    backtester_ensemble_errors['mean'][error] = value\n",
    "###############################################################################\n",
    "backtester_ensemble_weighted_average = BackTesterSimple(\n",
    "    error_methods=ALL_ERRORS,\n",
    "    data=ts,\n",
    "    params= model_ensemble_params,\n",
    "    train_percentage=80,\n",
    "    test_percentage=20, \n",
    "    model_class=WeightedAvgEnsemble)\n",
    "\n",
    "backtester_ensemble_weighted_average.run_backtest()\n",
    "\n",
    "backtester_ensemble_errors['weighted_average'] = {}\n",
    "for error, value in backtester_ensemble_weighted_average.errors.items():\n",
    "    backtester_ensemble_errors['weighted_average'][error] = value\n",
    "###############################################################################\n",
    "\n",
    "backtester_ensemble_bates_granger = BackTesterSimple(\n",
    "    error_methods=ALL_ERRORS,\n",
    "    data=ts,\n",
    "    params= model_ensemble_params,\n",
    "    train_percentage=80,\n",
    "    test_percentage=20, \n",
    "    model_class=BatesGrangerEnsemble)\n",
    "\n",
    "backtester_ensemble_bates_granger.run_backtest()\n",
    "\n",
    "backtester_ensemble_errors['bates&granger'] = {}\n",
    "for error, value in backtester_ensemble_bates_granger.errors.items():\n",
    "    backtester_ensemble_errors['bates&granger'][error] = value\n",
    "\n",
    "pd.DataFrame.from_dict(backtester_ensemble_errors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(backtester_ensemble_errors).round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(backtester_simple_errors).round()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".kats_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
